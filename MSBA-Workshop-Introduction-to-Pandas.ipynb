{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1lsxEkea04W0sEmt27PO4vzc8b7VflpWG","timestamp":1754586269586}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Introduction to Pandas\n","\n","This is a brief introduction to the `pandas` library in Python for working with datasets as pandas Data Frames. GSB 544 will cover Python for data science, including `pandas`, in much more detail."],"metadata":{"id":"JM0T4Dk-XG7z"}},{"cell_type":"markdown","metadata":{"id":"N4l5tHGE3TJK"},"source":["## Tabular Data\n","\n","What does data look like? For most people, the first image that comes to mind is a spreadsheet, where each row represents something for which information is being measured and each column a type of measurement. This stereotype exists for a reason; many real-world data sets can indeed be organized this way. Data that can be represented using rows and columns is called **tabular data**. The rows are also called **observations** or **records**,  while the columns are called **variables** or **fields**. The different terms reflect the diverse communities within data science, and their origins are summarized in the table below.\n","\n","|                     | Rows           | Columns     |\n","|---------------------|----------------|-------------|\n","| Statisticians       | \"observations\" | \"variables\" |\n","| Computer Scientists | \"records\"      | \"fields\"    |\n","\n","The table below is an example of a\n","data set that can be represented in tabular form.\n","This is a sample of user profiles in the\n","San Francisco Bay Area from the online dating website\n","OKCupid. In this case, each observation is an OKCupid user, and the variables include age, body type, height, and\n","(relationship) status. Although a\n","data table can contain values of all types, the\n","values within a column are typically all of the same\n","type---the age and height columns store\n","numbers, while the body type and\n","status columns store strings. Some values may be missing, such as body type for the first user\n","and diet for the second.\n","\n","| age | body type |        diet       | ... | smokes | height | status |\n","|-----|-----------|-------------------|-----|--------|--------|--------|\n","| 31  |           | mostly vegetarian | ... |   no   |   67   | single |\n","| 31  |  average  |                   | ... |   no   |   66   | single |\n","| 43  |   curvy   |                   | ... | trying to quit | 65 | single |\n","| ... |    ...    |       ...         | ... |  ...   |  ...   | ... |\n","| 60  |    fit    |                   | ... |   no   |   57   | single |\n","\n"]},{"cell_type":"markdown","source":["## Pandas\n","\n","Tabular data is essential for doing data science. But a structure for tabular data is not built into Python, so we need to import a library. That library is [Pandas](https://pandas.pydata.org/), which essentially does one thing---define a data structure called a `DataFrame` for storing tabular data. But this data structure is so fundamental to data science that importing `pandas` is the very first line of many Colab notebooks and Python scripts.\n","\n","Let's import `pandas`. The standard abbreviation for Pandas is `pd`."],"metadata":{"id":"qSb0BROzQi-g"}},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"UAczc7vuQqsT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Many data sets are stored as files on disk, such as in **comma-separated values (CSV)** files [like this](https://raw.githubusercontent.com/kevindavisross/msba-workshop/refs/heads/main/cereals.csv). How do we get data into a `pandas` `DataFrame`? Pandas provides a function called `read_csv()` for reading in files in CSV format."],"metadata":{"id":"gQ6CLHiDGsi5"}},{"cell_type":"markdown","source":["## Reading in Data from a URL\n","\n","If the data file already lives on the Internet, then you can simply pass in the URL to `read_csv()`. We'll use a [data set](https://www.kaggle.com/datasets/crawford/80-cereals) where each row is a breakfast cereal."],"metadata":{"id":"YHmob7ZjByc8"}},{"cell_type":"code","source":["df_cereals = pd.read_csv(\"https://raw.githubusercontent.com/kevindavisross/msba-workshop/refs/heads/main/cereals.csv\")"],"metadata":{"id":"FPx8xvyxbrb5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Calling the data frame will display the first few and last few rows and columns."],"metadata":{"id":"yQpiYJiAMswN"}},{"cell_type":"code","source":["df_cereals"],"metadata":{"id":"u_nFBXjfMs7k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The `columns` method returns the column names."],"metadata":{"id":"ldM0oDLf6FLB"}},{"cell_type":"code","source":["df_cereals.columns"],"metadata":{"id":"hYht5RVF6ASl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we'll see how to use Pandas to perform some basic data science operations on a data set."],"metadata":{"id":"0gGGvw-qtPWe"}},{"cell_type":"markdown","source":["## Selecting Columns"],"metadata":{"id":"EmoO0WMye6lv"}},{"cell_type":"markdown","source":["You can select a single column by name"],"metadata":{"id":"8YIfJb1M5oqJ"}},{"cell_type":"code","source":["df_cereals[\"calories\"]"],"metadata":{"id":"6UTEp-us5l85"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Or select multiple columns by passing a list of names"],"metadata":{"id":"LV6ZP9SM532j"}},{"cell_type":"code","source":["df_cereals[[\"name\", \"rating\", \"calories\", \"mfr\"]]"],"metadata":{"id":"qwbuqMK654Cs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Mutating: Adding Columns"],"metadata":{"id":"7zVSPC2IfNrk"}},{"cell_type":"markdown","source":["We can create new columns from existing columns. For example, `sodium` is measured in milligrams but let's convert to grams."],"metadata":{"id":"XYdo-KsA7KjJ"}},{"cell_type":"code","source":["df_cereals[\"sodium\"] / 1000"],"metadata":{"id":"A7wQU0gb7KvS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can save new columns in the data frame"],"metadata":{"id":"Y982J3pB7K7p"}},{"cell_type":"code","source":["df_cereals[\"sodium_g\"] = df_cereals[\"sodium\"] / 1000\n","\n","df_cereals"],"metadata":{"id":"Y7dHmo1zHYc6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can also create new columns from multiple columns. Column operations are \"vectorized\" and applied row by row."],"metadata":{"id":"jpWYX-H_HgJW"}},{"cell_type":"code","source":["df_cereals[\"calories_per_cup\"] = df_cereals[\"calories\"] / df_cereals[\"cups\"]\n","\n","df_cereals"],"metadata":{"id":"Ffb_7WJP7LKZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Sorting (Arranging) Rows"],"metadata":{"id":"7ZMiqIpTfCbt"}},{"cell_type":"markdown","source":["We can sort (arrange) rows by the values in one or more columns."],"metadata":{"id":"aQY7KAaVKJ4p"}},{"cell_type":"code","source":["df_cereals.sort_values(by = \"calories\")"],"metadata":{"id":"ioKMGgQRKKER"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note that sorting does NOT change the order of the data frame."],"metadata":{"id":"IPhks9eXKmq9"}},{"cell_type":"code","source":["df_cereals"],"metadata":{"id":"JEM8UaK3KsiT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["If we want to save the sort order we can assign the sorted data frame to an object with either a new name, or the current name if we want to overwrite the originaldata frame. Below we sort first by `mfr` then by `calories_per_cup` within each value of `mfr`. (We're not going to worry about the index (the numbers on the left) in this tutorial.)"],"metadata":{"id":"HnJWBoKuKKQK"}},{"cell_type":"code","source":["df_cereals = df_cereals.sort_values(by = [\"mfr\", \"calories_per_cup\"])\n","\n","df_cereals"],"metadata":{"id":"9kbZVl8MKr1u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Filtering Rows"],"metadata":{"id":"AjBrRUZNe6om"}},{"cell_type":"markdown","metadata":{"id":"yF-G7EIXJtaV"},"source":["Choosing a subset of rows is called filtering. Usually we filter to obtain rows that satisfy some condition.\n","\n","The standard way to filter a `DataFrame` is to use a \"boolean mask\", a column of booleans (i.e., True/False values). The easiest way to create a boolean mask is to use one of the standard comparison operators `==`, `<`, `>`, and `!=` (not equal) on an existing column in the `DataFrame`. For example, the following code produces a boolean mask that is equal to `True` if `mfr` is \"G\" and `False` otherwise."]},{"cell_type":"code","metadata":{"id":"LaR02lRMJtaW"},"source":["df_cereals[\"mfr\"] == \"G\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fPlvq_-mJtad"},"source":["Notice that logical equality `==` is being applied in a vectorized way, row by row.\n","\n","Now, we can use the boolean mask as a filter on the `DataFrame` to extract the rows where the mask equals `True`."]},{"cell_type":"code","metadata":{"id":"1O6x3ZoZJtaf"},"source":["df_mfr_G = df_cereals[df_cereals[\"mfr\"] == \"G\"]\n","\n","df_mfr_G"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can filter based on multiple conditions using logical operators like `&` (and) or `|` (or)."],"metadata":{"id":"aYTWPTNORFwe"}},{"cell_type":"code","source":["df_cereals[(df_cereals[\"mfr\"] == \"G\") & (df_cereals[\"calories\"] > 125)]"],"metadata":{"id":"O7S4k43mRF-O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_cereals[(df_cereals[\"mfr\"] == \"G\") | (df_cereals[\"calories\"] > 125)]"],"metadata":{"id":"zlbCFw9HRdha"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can filter rows and select columns simultaneously."],"metadata":{"id":"t7ijyA2JR3pk"}},{"cell_type":"code","source":["df_cereals[df_cereals[\"mfr\"] == \"G\"][[\"name\", \"mfr\", \"calories\"]]"],"metadata":{"id":"5Q8MkTEFR302"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Summarizing"],"metadata":{"id":"7akxkd3LbiOz"}},{"cell_type":"markdown","source":["We can summarize a single column using descriptive statistics like `mean` (average) or `std` (standard deviation)."],"metadata":{"id":"WriWKmmGSQZ0"}},{"cell_type":"code","source":["df_cereals[\"calories\"].mean()"],"metadata":{"id":"M6e1O3UVSZju"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_cereals[\"calories\"].std()"],"metadata":{"id":"v1p3IlozSdlv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can summarize multiple columns"],"metadata":{"id":"lpQlqyB1Sowh"}},{"cell_type":"code","source":["df_cereals[[\"calories\", \"calories_per_cup\"]].mean()"],"metadata":{"id":"FdkAEVkYSo_3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The `describe` method provides a quick summary."],"metadata":{"id":"Q1blfO0wTCh5"}},{"cell_type":"code","source":["df_cereals[\"calories\"].describe()"],"metadata":{"id":"IPMgPe2zTMCE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_cereals[[\"calories\", \"calories_per_cup\"]].describe()"],"metadata":{"id":"aRhwhEC9bgev"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`describe` returns different summary statistics depending on whether the variable is categorical or numerical."],"metadata":{"id":"xAwKM7ARTfgd"}},{"cell_type":"code","source":["df_cereals[\"mfr\"].describe()"],"metadata":{"id":"konJ2EzGTcEs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For categorical variables `value_counts` provides a summary of values and their frequencies"],"metadata":{"id":"T4y90en6Sn_v"}},{"cell_type":"code","source":["df_cereals[\"mfr\"].value_counts()"],"metadata":{"id":"G9_xO-YPTxIB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`value_counts` also makes sense for discrete numerical variables that take a small set of possible values."],"metadata":{"id":"HHpHAQmAUIEa"}},{"cell_type":"code","source":["df_cereals[\"protein\"].value_counts()"],"metadata":{"id":"yiaCoCnjUQjN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Notice that the levels are sorted in decreasing order of frequency by default. We can sort by the values of the variable using `sort_index`."],"metadata":{"id":"wlQL_vnoUFgF"}},{"cell_type":"code","source":["df_cereals[\"mfr\"].value_counts().sort_index()"],"metadata":{"id":"czFittXHU9Qe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_cereals[\"protein\"].value_counts().sort_index()"],"metadata":{"id":"buwjKc26U9T1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Groupby"],"metadata":{"id":"x7efz-cCVaYC"}},{"cell_type":"markdown","source":["We often want to create summaries within groups. We can achieve this using `groupby`"],"metadata":{"id":"KOG5E2oNVabX"}},{"cell_type":"code","source":["df_cereals.groupby(\"mfr\")[\"calories\"].mean()"],"metadata":{"id":"I96XbBm-b39Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_cereals.groupby(\"mfr\")[\"calories\"].describe()"],"metadata":{"id":"60c0-VaGWnzf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can `groupby` multiple variables."],"metadata":{"id":"NZmU-tiVXAAA"}},{"cell_type":"code","source":["df_cereals.groupby([\"mfr\", \"type\"])[\"calories\"].describe()"],"metadata":{"id":"_1SrFDz3_DRr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Reading in Data from a File on your Computer\n","\n","If you instead want to read in a data file on your computer, you can pass in the path to the file (e.g., `\"/home/data/mydata.csv\"`) to `read_csv()`.\n","\n","There's just one catch. Colab is a cloud service; it can't read files on your computer. In order to read in a data file from Colab, you have to upload the file to the Colab file system.\n","\n","Instructions:\n","\n","1. Click on the folder icon in the left toolbar. This will open up a pane that allows you to interact with the Colab file system.\n","2. Click on the upload icon and find the file that you want to upload.\n","\n","Now the data file is on the Colab file system, so we can read it in using `read_csv()`. By default, files get uploaded to `/content/`. If you get a `FileNotFoundError`, double check where you uploaded the file."],"metadata":{"id":"ICnnjxCSWq7S"}},{"cell_type":"code","source":["# You'll need to first ownload the cereals.csv file from:\n","# https://github.com/kevindavisross/msba-workshop/blob/main/cereals.csv\n","# Once it is on your computer, you can upload the file to Colab using the instructions above\n","\n","\n","df_cereal = pd.read_csv(\"/content/cereals.csv\")\n","\n","df_cereal"],"metadata":{"id":"YSJ97VqmWzHM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Exercises"],"metadata":{"id":"lQQSreVk94oQ"}},{"cell_type":"markdown","metadata":{"id":"_oX5P21VM0Q8"},"source":["A frequently used example data set is the Ames housing data set which consists of residential properties in Ames, Iowa from 2006 to 2010. For more information about the variables in this data set, please refer to the [data documentation](https://jse.amstat.org/v19n3/decock/DataDocumentation.txt).\n","\n","There are a few ways to do each of the exercises below, but **the answer to each should be a single line of code, using the data science operations introduced above as much as possible**. (If you're using for loops or writing Python functions or using Python lambdas, you're overcomplicating it.)"]},{"cell_type":"markdown","source":["Read in the data set from: https://raw.githubusercontent.com/kevindavisross/data301/main/data/AmesHousing.txt.\n","\n","Note: First click on the link and look at the file. The data set is stored in a tab-separated values file, rather than a CSV. We can still use `read_csv`, but we need to specify the delimiter (tab rather than comma) with the argument `sep=\"\\t\"`."],"metadata":{"id":"vJmUvclA1dMO"}},{"cell_type":"code","source":["# your code here"],"metadata":{"id":"avJFIOy2Jhgq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note that only certain columns are displayed. What are all the columns?"],"metadata":{"id":"hbbZW2qbxwxu"}},{"cell_type":"code","source":["# your code here"],"metadata":{"id":"Lm5qgSWDxw_B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create a new data frame with just the columns `Neighborhood`, `Lot Area`, `Gr Liv Area`, `Yr Sold`,  and `SalePrice`."],"metadata":{"id":"fBABDxzuuC2x"}},{"cell_type":"code","source":["# your code here"],"metadata":{"id":"86UF_Tz_uDA6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`Lot Area` is measured in acres; convert it to square feet; replace the existing values (in acres). Note: there 43560 square feet in an acre."],"metadata":{"id":"44JnwgtSvhfu"}},{"cell_type":"code","source":["# your code here"],"metadata":{"id":"6ejdyEnvvhq6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`Gr Liv Area` is the square footage of the house. Create a `Price per Sqft` variable."],"metadata":{"id":"mKwRJst_uDMp"}},{"cell_type":"code","source":["# your code here"],"metadata":{"id":"kyYkLk1JuDX0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sort the data frame by `SalePrice` within `Neighborhood` and save the sorted data frame."],"metadata":{"id":"e-YXHluhuDix"}},{"cell_type":"code","source":["# your code here"],"metadata":{"id":"DGThWbfwuDtN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create a data frame with just the houses sold in 2010."],"metadata":{"id":"hrKWAM6-uD3m"}},{"cell_type":"code","source":["# your code here"],"metadata":{"id":"zpFqUYlGuECD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create a data frame with just the houses sold in 2010 with sale price less than 200,000."],"metadata":{"id":"-bXJiUNPz9OE"}},{"cell_type":"code","source":["# your chode here"],"metadata":{"id":"XBuVvyrX0K7C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Find the mean sale price for all the houses."],"metadata":{"id":"egDoqJmW0kDH"}},{"cell_type":"code","source":["# your code here"],"metadata":{"id":"SyHgXNr80kOV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Find descriptive statistics for the variables sale price, lot area, square footage, and price per sqft."],"metadata":{"id":"9zhqYmwG0kZz"}},{"cell_type":"code","source":["# your code here"],"metadata":{"id":"xrq9Xf0w1cQr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Find how many houses were sold in each year, sorted by year."],"metadata":{"id":"4eTy0hJs1K0f"}},{"cell_type":"code","source":["# your code here"],"metadata":{"id":"bd23rRfW1LCR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Within each neighborhood find the mean of sale price."],"metadata":{"id":"VhP8-sbM2O2O"}},{"cell_type":"code","source":["# your code here"],"metadata":{"id":"03Kpm-502PAX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Within each neighborhood find the mean of each of sale price, lot area, square footage, and price per sqft."],"metadata":{"id":"zt-b6Xz721ly"}},{"cell_type":"code","source":["# your code here"],"metadata":{"id":"KGCOCL3c26JQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Find descriptive statistics for the sale price within each year sold."],"metadata":{"id":"SVaxasiL2PKx"}},{"cell_type":"code","source":["# your code here"],"metadata":{"id":"DpLJoZ8a3IFV"},"execution_count":null,"outputs":[]}]}